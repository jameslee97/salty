{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import salty\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4388: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  object.__getattribute__(self, name)\n",
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4389: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  return object.__setattr__(self, name, value)\n"
     ]
    }
   ],
   "source": [
    "devmodel = salty.aggregate_data(['thermal_conductivity'], T=[100, 700], P=[99, 102])\n",
    "devmodel.Data['smiles_string'] = devmodel.Data['smiles-cation'] + \".\" + devmodel.Data['smiles-anion']\n",
    "values = devmodel.Data['smiles_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCCCCCCCn1cc[n+](c1)C.[B-](F)(F)(F)F\n"
     ]
    }
   ],
   "source": [
    "print(values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: CCCCCCCCn1cc[n+](c1)C.[B-](F)(F)(F)F\n",
      "inverted: ['CCCCCCCCn1cc[n+](c1)C.[B-](F)(F)(F)F']\n"
     ]
    }
   ],
   "source": [
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "print(\"input:\", values[0])\n",
    "print(\"inverted:\", inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(x_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 61)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 474 samples, validate on 157 samples\n",
      "Epoch 1/5\n",
      "474/474 [==============================] - 0s 1ms/step - loss: 0.2436 - val_loss: 0.2346\n",
      "Epoch 2/5\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.2176 - val_loss: 0.1942\n",
      "Epoch 3/5\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.1602 - val_loss: 0.1205\n",
      "Epoch 4/5\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.0850 - val_loss: 0.0541\n",
      "Epoch 5/5\n",
      "474/474 [==============================] - 0s 93us/step - loss: 0.0384 - val_loss: 0.0275\n"
     ]
    }
   ],
   "source": [
    "m = Sequential()\n",
    "m.add(Dense(20,  activation='elu', input_shape=(61,)))\n",
    "m.add(Dense(2,    activation='linear', name=\"bottleneck\"))\n",
    "m.add(Dense(20,  activation='elu'))\n",
    "m.add(Dense(61,  activation='sigmoid'))\n",
    "m.compile(loss='mean_squared_error', optimizer = Adam())\n",
    "history = m.fit(x_train, x_train, batch_size=20, epochs=5, verbose=1, \n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "encoder = Model(m.input, m.get_layer('bottleneck').output)\n",
    "Zenc = encoder.predict(x_train)  # bottleneck representation\n",
    "Renc = m.predict(x_train)        # reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
