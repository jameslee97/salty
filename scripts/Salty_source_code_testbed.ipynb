{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(df, path_or_buf='../salty/data/d3_web_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job will perform 10 tests for lambda\n",
      "Job 0 % complete\n",
      "Job complete\n"
     ]
    }
   ],
   "source": [
    "datadf = pd.DataFrame.from_csv('../salty/data/salts_with_descriptors.csv')\n",
    "datadf = datadf.reset_index(drop=False)#.sample(frac=1)\n",
    "datadf = datadf.loc[:, (datadf != 0).any(axis=0)] #remove columns where all values are 0\n",
    "datadf.dropna(inplace=True) #remove empty columns and rows with NaN \n",
    "# datadf = datadf.loc[datadf[\"NAME_CAT\"] != \"1-ethyl-3-methylimidazolium\"] #create subset\n",
    "\n",
    "datadf = datadf.sample(frac=1).reset_index(drop=True)\n",
    "anilist = datadf['NAME_ANI']\n",
    "catlist = datadf['NAME_CAT']\n",
    "saltlist = datadf[\"salt_name\"]\n",
    "\n",
    "datadf = datadf.drop('NAME_CAT',1) #remove non-numeric columns and normalize values\n",
    "datadf = datadf.drop('NAME_ANI',1)\n",
    "datadf = datadf.drop(\"salt_name\",1)\n",
    "\n",
    "df, alphas = compareAlphas(datadf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compareAlphas(datadf, alpha_array=np.arange(1,0,-1e-1), SSF=0.5, tol_boot=1e-6, MSSI=20, \\\n",
    "                  tol_lasso=1e-10, wrapper=False, display=False):\n",
    "    \"\"\"\n",
    "    hyperparameters are lambda (alpha), shuffle splitfraction (SSF), convergence critiera/allowance (tol)\n",
    "    maximum shuffle split iterations (MSSI)\n",
    "    \"\"\"\n",
    "    data=np.array(datadf)\n",
    "     \n",
    "    print('Job will perform %s tests for lambda' % len(alpha_array))\n",
    "#     lambda_test_MSE_averages=[]\n",
    "    n = data.shape[0]\n",
    "    d = data.shape[1]\n",
    "    d -= 1\n",
    "    n_train = int(n*SSF) #set fraction of data to be for training\n",
    "    n_test  = n - n_train\n",
    "    \n",
    "    X_train = np.zeros((n_train,d)) #prepare train/test arrays\n",
    "    X_test  = np.zeros((n_test,d))\n",
    "    Y_train = np.zeros((n_train))\n",
    "    Y_test = np.zeros((n_test))\n",
    "    X_train[:] = data[:n_train,:-1] #fill arrays according to train/test split\n",
    "    Y_train[:] = np.log(data[:n_train,-1].astype(float))\n",
    "    X_test[:] = data[n_train:,:-1]\n",
    "    Y_test[:] = np.log(data[n_train:,-1].astype(float))\n",
    "    \n",
    "    #initiate dataframe   \n",
    "    df = pd.DataFrame(np.log(datadf[\"Density_kg/m\"][n_train:]))\n",
    "    df[\"Temperature (K)\"]=datadf[\"Temperature_K\"][n_train:]\n",
    "    df[\"Pressure (kPa)\"]=datadf[\"Pressure_kPa\"][n_train:]\n",
    "    df[\"Salt Name\"]=saltlist[n_train:]\n",
    "\n",
    "    for j in range(len(alpha_array)):\n",
    "        \n",
    "        ###Train the LASSO model\n",
    "        model = Lasso(alpha=alpha_array[j],tol=tol_lasso,max_iter=2000)\n",
    "        model.fit(X_train,Y_train)\n",
    "        df[\"Prediction for alpha of %s\" % alpha_array[j]] = model.predict(X_test)\n",
    "        \n",
    "        ###Calculate test set MSE\n",
    "#         Y_hat =model.predict(X_test)\n",
    "#         n = len(Y_test)\n",
    "#         test_MSE = np.sum((Y_test-Y_hat)**2)**1/n\n",
    "#         test_MSE_array.append(test_MSE)\n",
    "\n",
    "#         lambda_test_MSE.append(np.average(test_MSE_array))\n",
    "#         Y_hats.append()\n",
    "        \n",
    "        if wrapper==False:\n",
    "            if (j+1/len(alpha_array)*10)%10 == 0:\n",
    "                print('Job %s' % str(j+1/len(alpha_array)*10), r'% complete' )\n",
    "#     df=pd.DataFrame(to_save)#,columns=[\"Density_kg/m, Experimental\",\\\n",
    "                #\"Density_kg/m, Prediction\", \"Salt Name\", \"Temperature_K\" , \"Pressure_kPa\"])\n",
    "#     if display:\n",
    "#         displayResult(alpha_array, lambda_test_MSE_averages)\n",
    "#         displayFeatures(optimum_lambda, tol_lasso, X_train, Y_train, data, datadf)\n",
    "#     optimum_lambda = alpha_array[lambda_test_MSE_averages.index(min(lambda_test_MSE_averages))]\n",
    "    print('Job complete')\n",
    "    return df, alpha_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from scipy.stats import mode\n",
    "from sklearn.linear_model import LassoLarsIC\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy.random import randint\n",
    "import numpy.linalg as LINA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def checkName(user_query, index=False):\n",
    "    \"\"\"\n",
    "    checkName uses a database lookup to return either SMILES or IUPAC \n",
    "    names of salts given either one of those are provided as inputs.\n",
    "    Default behavior is to return the SMILES encoding of a salt given\n",
    "    the salt name as input.\n",
    "    \n",
    "    Parameters\n",
    "    ------------------\n",
    "    user_query : str\n",
    "        string that will be used to query the database.\n",
    "        \n",
    "    Returns\n",
    "    ------------------\n",
    "    output: str\n",
    "        either the name of the salt, cation, or anion; or SMILES of the\n",
    "        salt, cation, or anion (SMILES for the salt are written as the \n",
    "        cation and ion SMILES strings separated by a comma)\n",
    "    \"\"\"\n",
    "    ###Check to see that the database is present\n",
    "    if os.path.isfile('../salty/data/saltInfo.csv') == False:\n",
    "        print('database file missing... exiting')\n",
    "        quit()\n",
    "    df = pd.read_csv('../salty/data/saltInfo.csv').astype(str)\n",
    "\n",
    "    try:\n",
    "        target_lookup = df.loc[(df == user_query).any(axis=1),:]\n",
    "        input_type = df.loc[:,(df == user_query).any(axis=0)].columns.values\n",
    "        target_column_index = df.columns.get_loc(input_type[0])\n",
    "        target_row_index = df.loc[(df == user_query).any(axis=1),:].index.tolist()[0]\n",
    "\n",
    "    except:\n",
    "        print(\"query %s not found\" % target_lookup)\n",
    "        return 0\n",
    "\n",
    "    #row_index pairs 1-4, 2-5, and 3-6\n",
    "    if target_column_index == 1 or target_column_index == 2 or target_column_index == 3:\n",
    "        print(\"user has queried with a SMILES structure\")\n",
    "        target = target_lookup.iloc[0][target_column_index+3]\n",
    "    else:\n",
    "        print(\"user has queried with a name\")\n",
    "        target = target_lookup.iloc[0][target_column_index-3]\n",
    "    print(\"your query has returned %s\" % target)\n",
    "    if index:\n",
    "        return target, target_row_index\n",
    "    else:\n",
    "        return target\n",
    "def wesCVLasso(datadf, alpha_array=np.arange(1,0,-1e-2), wrapper=False, tol_lasso=1e-10, display=False,\\\n",
    "              cv=5):\n",
    "    \"\"\"\n",
    "    hyperparameters are lambda (alpha), bootstrap splitfraction (BSF), convergence critiera/allowance (tol)\n",
    "    maximum number of bootstrap iterations (NBI)\n",
    "    \"\"\"\n",
    "    print('Job will perform %s tests for lambda' % len(alpha_array))\n",
    "    \n",
    "    data=np.array(datadf)\n",
    "    n = data.shape[0]\n",
    "    d = data.shape[1]\n",
    "    d -= 1\n",
    "    n_train = int(n*(1-1/cv)) #split size according to cv value)\n",
    "    n_test  = n - n_train\n",
    "    for j in range(cv):\n",
    "        data = np.random.permutation(data) #if you delete, will not be random ie separate by group\n",
    "        X_train = np.zeros((n_train,d)) #prepare train/test arrays\n",
    "        X_test  = np.zeros((n_test,d))\n",
    "        Y_train = np.zeros((n_train))\n",
    "        Y_test = np.zeros((n_test))\n",
    "        X_train[:] = data[:n_train,:-1] #fill arrays according to train/test split\n",
    "        Y_train[:] = np.log(data[:n_train,-1].astype(float))\n",
    "        X_test[:] = data[n_train:,:-1]\n",
    "        Y_test[:] = np.log(data[n_train:,-1].astype(float))\n",
    "        averages=np.zeros(len(alpha_array))\n",
    "        variances=np.zeros(len(alpha_array))\n",
    "\n",
    "        for i in range(len(alpha_array)):\n",
    "            ###Train the LASSO model\n",
    "            model = Lasso(alpha=alpha_array[i],tol=tol_lasso,max_iter=2000)\n",
    "\n",
    "            ###Calculate MSE\n",
    "            scores = cross_val_score(model, X_train, Y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "            avg = np.average(scores)\n",
    "            std = np.std(scores)\n",
    "            averages[i] = avg\n",
    "            variances[i] = std\n",
    "            optimum_alpha=alpha_array[np.argmin(np.absolute(averages))]\n",
    "    if display:\n",
    "        displayResult(alpha_array, averages, variances=variances, error=True)\n",
    "        displayFeatures(optimum_alpha, tol_lasso, X_train, Y_train, data, datadf)\n",
    "    print('Job complete')\n",
    "    return averages, variances, alpha_array\n",
    "\n",
    "def CVLasso(datadf, alpha_array=np.arange(1,0,-1e-2), wrapper=False, tol_lasso=1e-10, display=False):\n",
    "    \"\"\"\n",
    "    hyperparameters are lambda (alpha), bootstrap splitfraction (BSF), convergence critiera/allowance (tol)\n",
    "    maximum number of bootstrap iterations (NBI)\n",
    "    \"\"\"\n",
    "    print('Job will perform %s tests for lambda' % len(alpha_array))\n",
    "    \n",
    "    data=np.array(datadf)\n",
    "    n = data.shape[0]\n",
    "    d = data.shape[1]\n",
    "    d -= 1\n",
    "    n_train = int(n*1) #note I've set this to 1, crossvalscore is taking care of the actual splits\n",
    "    n_test  = n - n_train\n",
    "\n",
    "    data = np.random.permutation(data) #if you delete, will not be random ie separate by group\n",
    "    X_train = np.zeros((n_train,d)) #prepare train/test arrays\n",
    "    X_test  = np.zeros((n_test,d))\n",
    "    Y_train = np.zeros((n_train))\n",
    "    Y_test = np.zeros((n_test))\n",
    "    X_train[:] = data[:n_train,:-1] #fill arrays according to train/test split\n",
    "    Y_train[:] = np.log(data[:n_train,-1].astype(float))\n",
    "    X_test[:] = data[n_train:,:-1]\n",
    "    Y_test[:] = np.log(data[n_train:,-1].astype(float))\n",
    "    averages=np.zeros(len(alpha_array))\n",
    "    variances=np.zeros(len(alpha_array))\n",
    "\n",
    "    for i in range(len(alpha_array)):\n",
    "        ###Train the LASSO model\n",
    "        model = Lasso(alpha=alpha_array[i],tol=tol_lasso,max_iter=2000)\n",
    "        \n",
    "        ###Calculate MSE\n",
    "        scores = cross_val_score(model, X_train, Y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "        avg = np.average(scores)\n",
    "        std = np.std(scores)\n",
    "        averages[i] = avg\n",
    "        variances[i] = std\n",
    "        optimum_alpha=alpha_array[np.argmin(np.absolute(averages))]\n",
    "        if wrapper==False:\n",
    "            if (i+1/len(alpha_array)*10)%10 == 0:\n",
    "                print('Job %s' % str(i+1/len(alpha_array)*10), r'% complete' )\n",
    "    if display:\n",
    "        displayResult(alpha_array, averages, variances=variances, error=True)\n",
    "        displayFeatures(optimum_alpha, tol_lasso, X_train, Y_train, data, datadf)\n",
    "    print('Job complete')\n",
    "    return averages, variances, alpha_array\n",
    "\n",
    "def CVLassoValidationSet(datadf, data, test_data, alpha_array=np.arange(1,0,-1e-2), wrapper=False,\\\n",
    "                         tol_lasso=1e-10, display=False):\n",
    "    \"\"\"\n",
    "    CV WITH VALIDATION SET\n",
    "    \n",
    "    hyperparameters are lambda (alpha), bootstrap splitfraction (BSF), convergence critiera/allowance (tol)\n",
    "    maximum number of bootstrap iterations (NBI)\n",
    "    \"\"\"\n",
    "    print('Job will perform %s tests for lambda' % len(alpha_array))\n",
    "    \n",
    "    n = data.shape[0]\n",
    "    d = data.shape[1]\n",
    "    d -= 1\n",
    "    n_train = int(n*1) #note I've set this to 1.\n",
    "    n_test  = n - n_train\n",
    "\n",
    "    data = np.random.permutation(data) #if you delete, will not be random ie separate by group\n",
    "    X_train = np.zeros((n_train,d)) #prepare train/test arrays\n",
    "    X_test  = np.zeros((n_test,d))\n",
    "    Y_train = np.zeros((n_train))\n",
    "    Y_test = np.zeros((n_test))\n",
    "    X_train[:] = data[:n_train,:-1] #fill arrays according to train/test split\n",
    "    Y_train[:] = np.log(data[:n_train,-1].astype(float))\n",
    "    X_test[:] = data[n_train:,:-1]\n",
    "    Y_test[:] = np.log(data[n_train:,-1].astype(float))\n",
    "    averages=np.zeros(len(alpha_array))\n",
    "    variances=np.zeros(len(alpha_array))\n",
    "\n",
    "    for i in range(len(alpha_array)):\n",
    "        ###Train the LASSO model\n",
    "        model = Lasso(alpha=alpha_array[i],tol=tol_lasso,max_iter=2000)\n",
    "        \n",
    "        ###Calculate MSE\n",
    "        scores = cross_val_score(model, X_train, Y_train, cv=20, scoring='neg_mean_squared_error')\n",
    "        avg = np.average(scores)\n",
    "        std = np.std(scores)\n",
    "        averages[i] = avg\n",
    "        variances[i] = std\n",
    "        optimum_alpha=alpha_array[np.argmin(np.absolute(averages))]\n",
    "        if wrapper==False:\n",
    "            if (i+1/len(alpha_array)*10)%10 == 0:\n",
    "                print('Job %s' % str(i+1/len(alpha_array)*10), r'% complete' )\n",
    "    if display:\n",
    "        displayResult(alpha_array, averages, variances=variances, error=True)\n",
    "        displayFeatures(optimum_alpha, tol_lasso, X_train, Y_train, data, datadf)\n",
    "    print('Job complete')\n",
    "    return averages, variances, alpha_array\n",
    "\n",
    "\n",
    "def bootstrapLasso(datadf, alpha_array=np.arange(1,0,-1e-2), BSF=0.5, tol_boot=1e-6, MBI=100, \\\n",
    "                  tol_lasso=1e-10, wrapper=False, display=False):\n",
    "    \"\"\"\n",
    "    hyperparameters are lambda (alpha), bootstrap splitfraction (BSF), convergence critiera/allowance (tol)\n",
    "    aximum bootstrap iterations (MBI)\n",
    "    \"\"\"\n",
    "    data=np.array(datadf)\n",
    "    print('Job will perform %s tests for lambda' % len(alpha_array))\n",
    "    lambda_test_MSE_averages=[]\n",
    "    for j in range(len(alpha_array)):\n",
    "        test_MSE_array=[]\n",
    "        for i in range(MBI):\n",
    "            n = data.shape[0]\n",
    "            d = data.shape[1]\n",
    "            d -= 1\n",
    "            n_train = int(n*BSF) #set fraction of data to be for training\n",
    "            n_test  = n - n_train\n",
    "            data = np.random.permutation(data) #if you delete, will not be random ie separate by group\n",
    "            X_train = np.zeros((n_train,d)) #prepare train/test arrays\n",
    "            X_test  = np.zeros((n_test,d))\n",
    "            Y_train = np.zeros((n_train))\n",
    "            Y_test = np.zeros((n_test))\n",
    "            \n",
    "            ###sample from training set with replacement\n",
    "            for k in range(n_train):\n",
    "                x = randint(0,n_train)\n",
    "                X_train[k] = data[x,:-1]\n",
    "                Y_train[k] = np.log(data[x,-1].astype(float))\n",
    "            \n",
    "            ###sample from test set with replacement\n",
    "            for k in range(n_test):\n",
    "                x = randint(n_train,n)\n",
    "                X_test[k] = data[x,:-1]\n",
    "                Y_test[k] = np.log(data[x,-1].astype(float))\n",
    "\n",
    "\n",
    "            ###Train the LASSO model\n",
    "            model = Lasso(alpha=alpha_array[j],tol=tol_lasso,max_iter=2000)\n",
    "            model.fit(X_train,Y_train)\n",
    "\n",
    "            \n",
    "            ###Calculate test set MSE\n",
    "            Y_hat =model.predict(X_test)\n",
    "            n = len(Y_test)\n",
    "            test_MSE = np.sum((Y_test-Y_hat)**2)**1/n\n",
    "            test_MSE_array.append(test_MSE)\n",
    "            if i > 0:\n",
    "                conv_test = (np.average(test_MSE_array[:]) - np.average(test_MSE_array[:-1]))**2\n",
    "                if conv_test < tol_boot:\n",
    "                    break\n",
    "            if i == MBI:\n",
    "                print(\"%s lambda value did not converge\" % alpha_array[j])\n",
    "        lambda_test_MSE_averages.append(np.average(test_MSE_array))\n",
    "        optimum_lambda = alpha_array[lambda_test_MSE_averages.index(min(lambda_test_MSE_averages))]\n",
    "        if wrapper==False:\n",
    "            if (j+1/len(alpha_array)*10)%10 == 0:\n",
    "                print('Job %s' % str(j+1/len(alpha_array)*10), r'% complete' )\n",
    "    if display:\n",
    "        displayResult(alpha_array, lambda_test_MSE_averages)\n",
    "        displayFeatures(optimum_lambda, tol_lasso, X_train, Y_train, data, datadf)\n",
    "    print('Job complete')\n",
    "    return lambda_test_MSE_averages, alpha_array\n",
    "\n",
    "\n",
    "def bootstrapLassoInvisibleTest(datadf, data, test_data, alpha_array=np.arange(1,0,-1e-2), BSF=0.8, \\\n",
    "                                tol_boot=1e-10, MBI=100, tol_lasso=1e-10, wrapper=False, TSF=0.8,\\\n",
    "                               display=False):\n",
    "    \"\"\"\n",
    "    BOOTSTRAP WITH COMPLETELY SEPARATE TEST SET\n",
    "    \n",
    "    hyperparameters are lambda (alpha), bootstrap splitfraction (BSF), convergence critiera/allowance (tol)\n",
    "    maximum number of bootstrap iterations (MBI)\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import Lasso\n",
    "    print('Job will perform %s tests for lambda with %s reserved for validation and %s test set'\\\n",
    "          % (len(alpha_array), TSF, BSF))\n",
    "    lambda_test_MSE_averages=[]\n",
    "    for j in range(len(alpha_array)):\n",
    "        test_MSE_array=[]\n",
    "        for i in range(MBI):\n",
    "            n = data.shape[0]\n",
    "            d = data.shape[1]\n",
    "            n2 = test_data.shape[0]\n",
    "            d -= 1\n",
    "            n_train = int(n*BSF) #set fraction of data to be for training\n",
    "            n_test  = n2\n",
    "            data = np.random.permutation(data) #if you delete, will not be random ie separate by group\n",
    "            \n",
    "            X_train = np.zeros((n_train,d)) #prepare train/test arrays\n",
    "            X_test  = np.zeros((n_test,d))\n",
    "            Y_train = np.zeros((n_train))\n",
    "            Y_test = np.zeros((n_test))\n",
    "\n",
    "            ###sample from training set with replacement\n",
    "            for k in range(n_train):\n",
    "                x = randint(0,n_train)\n",
    "                X_train[k] = data[x,:-1]\n",
    "                Y_train[k] = np.log(data[x,-1].astype(float))\n",
    "            \n",
    "            ###sample from test set with replacement\n",
    "            for k in range(n_test):\n",
    "                y = randint(0,test_data.shape[0])\n",
    "                X_test[k] = test_data[y,:-1]\n",
    "                Y_test[k] = np.log(test_data[y,-1].astype(float))\n",
    "\n",
    "            ###Train the LASSO model\n",
    "            model = Lasso(alpha=alpha_array[j],tol=tol_lasso,max_iter=2000)\n",
    "            model.fit(X_train,Y_train)\n",
    "\n",
    "            ###Calculate test set MSE\n",
    "            Y_hat =model.predict(X_test)\n",
    "            n = len(Y_test)\n",
    "            test_MSE = np.sum((Y_test-Y_hat)**2)**1/n\n",
    "            test_MSE_array.append(test_MSE)\n",
    "            if i > 0:\n",
    "                conv_test = (np.average(test_MSE_array[:]) - np.average(test_MSE_array[:-1]))**2\n",
    "                if conv_test < tol_boot:\n",
    "                    break\n",
    "            if i == MBI:\n",
    "                print(\"%s lambda value did not converge\" % alpha_array[j])\n",
    "        lambda_test_MSE_averages.append(np.average(test_MSE_array))\n",
    "        if (j+1/len(alpha_array)*10)%10 == 0:# and wrapper==False:\n",
    "            print('Job %s' % str(j+1/len(alpha_array)*10), r'% complete' )\n",
    "    optimum_lambda = alpha_array[lambda_test_MSE_averages.index(min(lambda_test_MSE_averages))]\n",
    "    print(\"Job complete, optimum lambda converged on %s\" % optimum_lambda)\n",
    "    if display:\n",
    "        displayResult(alpha_array, lambda_test_MSE_averages)\n",
    "        displayFeatures(optimum_lambda, tol_lasso, X_train, Y_train, data, datadf)\n",
    "    return lambda_test_MSE_averages, alpha_array\n",
    "\n",
    "def shuffleSplitLasso(datadf, alpha_array=np.arange(1,0,-1e-2), SSF=0.5, tol_boot=1e-6, MSSI=300, \\\n",
    "                  tol_lasso=1e-10, wrapper=False, display=False):\n",
    "    \"\"\"\n",
    "    hyperparameters are lambda (alpha), shuffle splitfraction (SSF), convergence critiera/allowance (tol)\n",
    "    maximum shuffle split iterations (MSSI)\n",
    "    \"\"\"\n",
    "    data=np.array(datadf)\n",
    "     \n",
    "    print('Job will perform %s tests for lambda' % len(alpha_array))\n",
    "    lambda_test_MSE_averages=[]\n",
    "    for j in range(len(alpha_array)):\n",
    "        test_MSE_array=[]\n",
    "        for i in range(MSSI):\n",
    "            n = data.shape[0]\n",
    "            d = data.shape[1]\n",
    "            d -= 1\n",
    "            n_train = int(n*SSF) #set fraction of data to be for training\n",
    "            n_test  = n - n_train\n",
    "            data = np.random.permutation(data) #if you delete, will not be random ie separate by group\n",
    "            X_train = np.zeros((n_train,d)) #prepare train/test arrays\n",
    "            X_test  = np.zeros((n_test,d))\n",
    "            Y_train = np.zeros((n_train))\n",
    "            Y_test = np.zeros((n_test))\n",
    "            X_train[:] = data[:n_train,:-1] #fill arrays according to train/test split\n",
    "            Y_train[:] = np.log(data[:n_train,-1].astype(float))\n",
    "            X_test[:] = data[n_train:,:-1]\n",
    "            Y_test[:] = np.log(data[n_train:,-1].astype(float))\n",
    "\n",
    "            ###Train the LASSO model\n",
    "            model = Lasso(alpha=alpha_array[j],tol=tol_lasso,max_iter=2000)\n",
    "            model.fit(X_train,Y_train)\n",
    "\n",
    "            ###Calculate test set MSE\n",
    "            Y_hat =model.predict(X_test)\n",
    "            n = len(Y_test)\n",
    "            test_MSE = np.sum((Y_test-Y_hat)**2)**1/n\n",
    "            test_MSE_array.append(test_MSE)\n",
    "            if i > 0:\n",
    "                conv_test = (np.average(test_MSE_array[:]) - np.average(test_MSE_array[:-1]))**2\n",
    "                if conv_test < tol_boot:\n",
    "                    break\n",
    "            if i == MSSI:\n",
    "                print(\"%s lambda value did not converge\" % alpha_array[j])\n",
    "        lambda_test_MSE_averages.append(np.average(test_MSE_array))\n",
    "        \n",
    "        if wrapper==False:\n",
    "            if (j+1/len(alpha_array)*10)%10 == 0:\n",
    "                print('Job %s' % str(j+1/len(alpha_array)*10), r'% complete' )\n",
    "    if display:\n",
    "        displayResult(alpha_array, lambda_test_MSE_averages)\n",
    "        displayFeatures(optimum_lambda, tol_lasso, X_train, Y_train, data, datadf)\n",
    "    optimum_lambda = alpha_array[lambda_test_MSE_averages.index(min(lambda_test_MSE_averages))]\n",
    "    print('Job complete')\n",
    "    return lambda_test_MSE_averages, alpha_array\n",
    "\n",
    "def shuffleSplitLassoInvisibleTest(datadf, data, test_data, alpha_array=np.arange(1,0,-1e-2), SSF=0.8, \\\n",
    "                                tol_boot=1e-10, MSSI=100, tol_lasso=1e-10, wrapper=False, display=False):\n",
    "    \"\"\"\n",
    "    BOOTSTRAP WITH COMPLETELY SEPARATE TEST SET\n",
    "    \n",
    "    hyperparameters are lambda (alpha), shuffle split fraction (SSF), convergence critiera/allowance (tol)\n",
    "    maximum number of shuffle split iterations (MSSI)\n",
    "    \"\"\"\n",
    "    print('Job will perform %s tests for lambda' % len(alpha_array))\n",
    "    lambda_test_MSE_averages=[]\n",
    "    for j in range(len(alpha_array)):\n",
    "        test_MSE_array=[]\n",
    "        for i in range(MSSI):\n",
    "            n = data.shape[0]\n",
    "            d = data.shape[1]\n",
    "            n2 = test_data.shape[0]\n",
    "            d -= 1\n",
    "            n_train = int(n*SSF) #set fraction of data to be for training\n",
    "            n_test  = n2\n",
    "            data = np.random.permutation(data) #if you delete, will not be random ie separate by group\n",
    "            \n",
    "            X_train = np.zeros((n_train,d)) #prepare train/test arrays\n",
    "            X_test  = np.zeros((n_test,d))\n",
    "            Y_train = np.zeros((n_train))\n",
    "            Y_test = np.zeros((n_test))\n",
    "            \n",
    "            X_train[:] = data[:n_train,:-1] #fill arrays according to train/test split\n",
    "            Y_train[:] = np.log(data[:n_train,-1].astype(float))\n",
    "            X_test[:] = test_data[:,:-1]\n",
    "            Y_test[:] = np.log(test_data[:,-1].astype(float))\n",
    "\n",
    "            ###Train the LASSO model\n",
    "            model = Lasso(alpha=alpha_array[j],tol=tol_lasso,max_iter=2000)\n",
    "            model.fit(X_train,Y_train)\n",
    "\n",
    "            ###Calculate test set MSE\n",
    "            Y_hat =model.predict(X_test)\n",
    "            n = len(Y_test)\n",
    "            test_MSE = np.sum((Y_test-Y_hat)**2)**1/n\n",
    "            test_MSE_array.append(test_MSE)\n",
    "            if i > 0:\n",
    "                conv_test = (np.average(test_MSE_array[:]) - np.average(test_MSE_array[:-1]))**2\n",
    "                if conv_test < tol_boot:\n",
    "                    break\n",
    "            if i == MSSI:\n",
    "                print(\"%s lambda value did not converge\" % alpha_array[j])\n",
    "        lambda_test_MSE_averages.append(np.average(test_MSE_array))\n",
    "        if (j+1/len(alpha_array)*10)%10 == 0 & wrapper==False:\n",
    "            print('Job %s' % str(j+1/len(alpha_array)*10), r'% complete' )\n",
    "    optimum_lambda = alpha_array[lambda_test_MSE_averages.index(min(lambda_test_MSE_averages))]\n",
    "    print(\"Job complete, optimum lambda converged on %s\" % optimum_lambda)\n",
    "    if display:\n",
    "        displayResult(alpha_array, lambda_test_MSE_averages)\n",
    "        displayFeatures(optimum_lambda, tol_lasso, X_train, Y_train, data, datadf)\n",
    "    return lambda_test_MSE_averages, alpha_array\n",
    "\n",
    "\n",
    "def displayFeatures(optimum_lambda, tol_lasso, X_train, Y_train, data, datadf):\n",
    "    model = Lasso(alpha=optimum_lambda,tol=tol_lasso)\n",
    "    model.fit(X_train,Y_train)\n",
    "    i=0\n",
    "    for a in range(len(data[0])-1):\n",
    "        if model.coef_[a] != 0:\n",
    "            print(a,datadf.columns[a])\n",
    "            i+=1\n",
    "    print(\"%s total features selected\" % i)\n",
    "    \n",
    "def displayResult(alpha_array, averages, variances=None, error=False):\n",
    "    optimum_alpha=alpha_array[np.argmin(np.absolute(averages))]\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        plt.figure(figsize=(14,14))\n",
    "        if error==False:\n",
    "            plt.plot(np.log(alpha_array), averages)\n",
    "        else:\n",
    "            plt.errorbar(np.log(alpha_array), np.absolute(averages), np.absolute(variances))\n",
    "            plt.plot(np.log(optimum_alpha), np.min(np.absolute(averages)), \\\n",
    "                c='r', marker='*', markersize=20, label=optimum_alpha)\n",
    "        plt.legend()\n",
    "        plt.ylabel('average MSE')\n",
    "        plt.xlabel('lambda')\n",
    "        plt.grid(False)\n",
    "        plt.show()\n",
    "        \n",
    "def myround(x, base):\n",
    "    return (float(base) * round(float(x)/float(base)))\n",
    "\n",
    "def validationWrapper(name_of_pickle, iterations=30, TSF=0.8, BSF=0.8, alpha_array=np.arange(1,0,-1e-2),\\\n",
    "                    invisible_test=False, method=\"bootstrap\"):\n",
    "    \"\"\"\n",
    "    wrapper for boostrapLassoInvisibleTest. TSF is the test split fraction, the \n",
    "    test MSE dataset that the bootstrap will not sample from for a given iteration.\n",
    "    \n",
    "    example usage:\n",
    "    \n",
    "    \"\"\"\n",
    "    datadf = pd.read_pickle(name_of_pickle)\n",
    "    data=np.array(datadf)\n",
    "    results=np.zeros((len(alpha_array),iterations))\n",
    "    for p in range(iterations):\n",
    "        print(\"performing iteration %s of %s\" % (p+1, iterations))\n",
    "        if invisible_test:\n",
    "            if method==\"bootstrap\":\n",
    "                dataRand = np.random.permutation(data)\n",
    "                n = data.shape[0]\n",
    "                n_train = int(n*TSF) #set fraction of data to be for training\n",
    "                result, returned_alpha_array = bootstrapLassoInvisibleTest(datadf, dataRand[:n_train,:],\\\n",
    "                        dataRand[n_train:,:], alpha_array=alpha_array, BSF=BSF, wrapper=True, TSF=TSF)\n",
    "        else:\n",
    "            if method==\"bootstrap\":\n",
    "                print(\"running bootstrap\")\n",
    "                result, returned_alpha_array = bootstrapLasso(datadf,\\\n",
    "                        alpha_array=alpha_array, BSF=BSF, wrapper=True,\\\n",
    "                        display=False)\n",
    "            elif method==\"shuffleSplit\":\n",
    "                print(\"running shuffle split\")\n",
    "                result, returned_alpha_array = shuffleSplitLasso(datadf,\\\n",
    "                        alpha_array=alpha_array, SSF=BSF, wrapper=True,\\\n",
    "                        display=False) \n",
    "            elif method==\"cv\":\n",
    "                print(\"running cross validation\")\n",
    "                result, returned_alpha_array = shuffleSplitLasso(datadf,\\\n",
    "                        alpha_array=alpha_array, wrapper=True,\\\n",
    "                        display=False) \n",
    "                \n",
    "        results[:,p]=result\n",
    "    avg = np.mean(results, axis=1)\n",
    "    std = np.std(results,ddof=1,axis=1)\n",
    "    return avg, std, results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
